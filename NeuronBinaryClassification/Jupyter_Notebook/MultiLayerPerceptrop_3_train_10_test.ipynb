{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('(#row,#column) of train dataset', (406, 46))\n",
      "('(#row,#column) of test dataset', (40, 46))\n"
     ]
    }
   ],
   "source": [
    "multi_layer_dup_train = pd.read_csv('../FeaturesCsvFile/featuresfile.csv')\n",
    "multi_layer_dup_test = pd.read_csv('../FeaturesCsvFile/featuresfile_10.csv')\n",
    "multi_layer_train = multi_layer_dup_train.drop_duplicates(subset=['User', 'Timestamp'])\n",
    "multi_layer_unique_test = multi_layer_dup_test.drop_duplicates(subset=['User', 'Timestamp'])\n",
    "multi_layer_test = multi_layer_unique_test.iloc[sample(range(len(multi_layer_unique_test)), 40), :]\n",
    "\n",
    "print ('(#row,#column) of train dataset' , multi_layer_train.shape)\n",
    "print ('(#row,#column) of test dataset' , multi_layer_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = multi_layer_train.values[:, 2:45]\n",
    "y_train = multi_layer_train.values[:, 45]\n",
    "X_test = multi_layer_test.values[:, 2:45]\n",
    "y_test = multi_layer_test.values[:, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  4]\n",
      " [ 4 16]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    running       0.80      0.80      0.80        20\n",
      "    walking       0.80      0.80      0.80        20\n",
      "\n",
      "avg / total       0.80      0.80      0.80        40\n",
      "\n",
      "\n",
      "Accuracy of Multi-layer Perceptron Score: 0.80\n",
      "\n",
      "Accuracy of Accuracy Score : 0.80\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(15,),max_iter=60)\n",
    "mlp.fit(X_train,y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('\\nAccuracy of Multi-layer Perceptron Score: %.2f' % mlp.score(X_test,y_test))\n",
    "print('\\nAccuracy of Accuracy Score : %.2f' % accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12235787  0.12789495 -0.02793496 -0.09468049  0.34952045  0.06809124\n",
      "  0.15163515 -0.07829524  0.02340041 -0.23713252 -0.07132879  0.09612821\n",
      "  0.26811775 -0.15395614  0.24343125]\n",
      "[ 0.23535623 -0.09516874  0.00616424  0.06468685 -0.12496201 -0.05622185\n",
      "  0.04855544  0.23379815 -0.09867524 -0.34023587  0.14924501  0.26556911\n",
      "  0.04464728  0.27203709  0.217442  ]\n",
      "[ 0.08613421 -0.12794671  0.19947432 -0.02344498 -0.01234894 -0.27173422\n",
      " -0.13101981 -0.10407447 -0.34683198  0.11086818  0.11289683  0.08894067\n",
      " -0.05136253  0.26465481  0.15672459]\n",
      "[ 0.09038637 -0.05976515  0.26870887 -0.07331945  0.2305423  -0.2029732\n",
      "  0.16132778  0.19267097 -0.06862219  0.1094099   0.27893252  0.26928647\n",
      " -0.13475411 -0.12132286 -0.05132219]\n",
      "[ 0.2421778  -0.37254126  0.04663032  0.26080324  0.14057909 -0.12460854\n",
      " -0.29030414  0.00129776 -0.28475944  0.3387149   0.32483152 -0.01635943\n",
      " -0.13357928  0.17629125  0.06750578]\n",
      "[-0.15751626  0.06736764 -0.03354816  0.15141176  0.07059152  0.16756554\n",
      " -0.42280424 -0.21816463  0.04279096  0.40452036  0.34184124  0.06113064\n",
      "  0.18480603 -0.02960807 -0.22242325]\n",
      "[-0.16325723 -0.08718096 -0.27540676 -0.0891154  -0.21703446  0.25932742\n",
      "  0.22646813 -0.16376085  0.32695912  0.22904118  0.00545482 -0.04267566\n",
      "  0.09657919  0.25925434  0.08745966]\n",
      "[ -2.01332612e-01  -2.05914117e-01  -2.66590278e-02   3.06178000e-01\n",
      "  -1.63175014e-01   7.03473176e-02   2.56239053e-01  -2.21133259e-01\n",
      "  -2.49802228e-01  -4.08213879e-02  -1.49801489e-01   8.14802041e-05\n",
      "  -2.92577531e-01  -2.62555066e-01  -2.24317080e-01]\n",
      "[ 0.06828279 -0.1752533  -0.33940128 -0.27322807 -0.18614199 -0.19461982\n",
      "  0.13339059 -0.22194547 -0.26730492  0.11413342  0.07547965 -0.23976741\n",
      "  0.2332997   0.0309562   0.2656507 ]\n",
      "[ 0.04841233 -0.27930018 -0.09253556 -0.00106891  0.34214654 -0.06386693\n",
      "  0.23963545 -0.16626088 -0.1117686   0.03403939 -0.28420784 -0.27151013\n",
      " -0.02985835  0.22080965 -0.25700411]\n",
      "[-0.15422252  0.29907632  0.28996008  0.20165747  0.09738539 -0.18217039\n",
      " -0.2148541  -0.00689456  0.25740653 -0.29477989  0.19080279  0.2281499\n",
      "  0.03832867  0.28437993  0.06548988]\n",
      "[-0.25457506  0.08144119 -0.04156898 -0.24764024  0.25052469  0.05394591\n",
      " -0.0077303  -0.26078089 -0.1657899   0.26311103  0.27310825 -0.00410224\n",
      "  0.26102001 -0.06794457 -0.12981578]\n",
      "[ 0.22465921  0.0447505   0.24426825 -0.03625884 -0.13297514 -0.31138257\n",
      " -0.05327716  0.05421491  0.04044492 -0.05281735 -0.15756045 -0.04135792\n",
      "  0.09813892  0.27592508  0.10321089]\n",
      "[-0.1320649  -0.15071673 -0.20691641  0.06206911  0.17014723 -0.09166188\n",
      "  0.25386074 -0.34773862  0.09578012  0.21416091  0.11956689  0.0626332\n",
      "  0.34975068 -0.34415807  0.17017862]\n",
      "[-0.07958514 -0.13674358  0.05577722  0.2694841   0.22231372  0.12362943\n",
      "  0.16743669  0.11913089  0.03772357 -0.00666485  0.07474918 -0.16961525\n",
      " -0.17279284 -0.03833493 -0.05288209]\n",
      "[ 0.18851351 -0.22809184 -0.14395061 -0.236758    0.13999873  0.23111877\n",
      "  0.30834818  0.01381205 -0.07937099 -0.16503075  0.24137093  0.01029095\n",
      "  0.17777522  0.02315863 -0.13617689]\n",
      "[ 0.26309474  0.21966122  0.13402668 -0.33800416  0.00672764 -0.00168768\n",
      " -0.16383009 -0.20810346 -0.31430949  0.28511402 -0.20926205 -0.13278413\n",
      "  0.06609054  0.0348436   0.01937539]\n",
      "[-0.05520709  0.02351212  0.14628282 -0.22021413 -0.26983288  0.08865748\n",
      "  0.10623453 -0.18537351 -0.20844331  0.06959323 -0.16318211 -0.08126279\n",
      "  0.24157793 -0.11315566 -0.00146811]\n",
      "[ 0.19442776 -0.14800096 -0.1221127  -0.07413833 -0.27932653  0.17495308\n",
      "  0.12853919 -0.26317648  0.21394729  0.08114899 -0.18012917  0.06283388\n",
      "  0.12645982  0.20314192 -0.16745856]\n",
      "[ 0.27248669  0.04278047  0.03579474  0.09465412 -0.29851183 -0.00247366\n",
      "  0.04453257 -0.01160466 -0.05039857  0.05641026  0.23026732  0.18272229\n",
      " -0.1075816  -0.31530445  0.24227722]\n",
      "[-0.00756834 -0.19089349 -0.30423871  0.31147502  0.02878884 -0.08427122\n",
      " -0.09763676 -0.27409114 -0.23686348  0.07675537 -0.03144922 -0.18747458\n",
      " -0.26295964  0.17366181  0.1642392 ]\n",
      "[ 0.03632788 -0.21362415  0.22314654 -0.18874731 -0.14708496 -0.30294151\n",
      "  0.25720742 -0.12101736  0.37214387 -0.17432523  0.28712306 -0.0918629\n",
      "  0.14507167  0.11274646 -0.17687614]\n",
      "[ 0.29291212  0.09852604 -0.21264122  0.0633952  -0.2799901  -0.13985009\n",
      "  0.16051905 -0.23209084  0.01026438  0.28166252  0.15374921  0.0289934\n",
      " -0.1456356  -0.02594107  0.00502014]\n",
      "[ 0.04591014 -0.17532094  0.29889398 -0.32213357  0.05051353  0.24809448\n",
      "  0.24888484 -0.22504163  0.04987754 -0.35586967  0.26759366 -0.23517299\n",
      " -0.17435976  0.24092598 -0.28136377]\n",
      "[-0.29887427  0.05066106 -0.08295194 -0.02257029  0.1543288  -0.0760376\n",
      " -0.23335061 -0.09423105 -0.22751534  0.03177739 -0.00056627 -0.21286791\n",
      " -0.13281485 -0.20513032 -0.26415566]\n",
      "[ 0.01611441 -0.18881302  0.23983606  0.22645397  0.23715466  0.29573193\n",
      "  0.19912936 -0.34397903  0.21321585 -0.03975161 -0.03190191  0.3260762\n",
      "  0.22665775 -0.18961529  0.23270833]\n",
      "[ 0.07421354 -0.21750639  0.15384843 -0.24166835  0.10856343  0.10115506\n",
      " -0.30726757  0.16791139  0.15720757 -0.15492622  0.2766904  -0.04607814\n",
      "  0.20543794 -0.2948849  -0.26526534]\n",
      "[ 0.10774653  0.08054898 -0.06024524 -0.33825319  0.04597725  0.29027932\n",
      "  0.22434884  0.27423226 -0.11319973  0.25744661  0.23203132 -0.12075996\n",
      "  0.09281142  0.09370682  0.35104181]\n",
      "[ 0.12477182 -0.11313245  0.04627463  0.21315347 -0.2955322   0.32773476\n",
      "  0.04697842 -0.13777176 -0.24628208 -0.13013941  0.08596963  0.23327114\n",
      "  0.15358436 -0.19923148 -0.01461038]\n",
      "[ 0.03624015 -0.27295414 -0.04940622 -0.10472227  0.24617129  0.00597619\n",
      "  0.21627704  0.16911696 -0.01027383  0.08218148  0.08671209 -0.3030793\n",
      " -0.0283523  -0.15427936 -0.2577142 ]\n",
      "[-0.2119467  -0.22502285  0.20173444  0.2679952  -0.32559755  0.24726272\n",
      "  0.09075377 -0.04022806  0.25323756  0.25413566  0.04621056 -0.45260234\n",
      "  0.22759855  0.11583852 -0.18008544]\n",
      "[-0.02265653  0.18725785 -0.04852577 -0.2336731   0.15751549  0.29081371\n",
      "  0.19059348  0.0717823   0.30133392  0.29038958  0.0234745  -0.27078887\n",
      "  0.10956276 -0.40304267 -0.19336054]\n",
      "[ 0.23601552 -0.37228271  0.22686303 -0.08261636  0.04702795  0.07109307\n",
      " -0.37755079  0.28591982 -0.12056339  0.39428938  0.25033056  0.12262373\n",
      "  0.22350852 -0.40479138  0.05153312]\n",
      "[-0.34364546  0.02168617 -0.28369641  0.17094343  0.03781881 -0.17290104\n",
      "  0.35445084 -0.01052899 -0.34336218 -0.36755299  0.07509346  0.21128516\n",
      " -0.07510606  0.33139599  0.18770756]\n",
      "[ 0.16297797  0.22902258 -0.13948543 -0.32642119 -0.08866194 -0.43700956\n",
      " -0.16994541 -0.35210873  0.22680553 -0.44658939  0.09819722  0.30008648\n",
      "  0.09862764 -0.15652502 -0.18580902]\n",
      "[-0.27567739 -0.1865537  -0.08297525 -0.17007812  0.18367765  0.03631655\n",
      "  0.14657108 -0.18150461 -0.03558697  0.06035697 -0.17801692  0.18761232\n",
      "  0.28712343  0.24736939 -0.02746144]\n",
      "[-0.03920728 -0.15781565  0.18342719  0.2883118  -0.12023841 -0.25462683\n",
      " -0.15825144  0.18407192  0.05506651  0.14490466 -0.13297677  0.35276909\n",
      "  0.34300223  0.10512868  0.06276742]\n",
      "[ 0.1309417   0.25784156 -0.07574997  0.26852656 -0.07250258  0.1596214\n",
      " -0.38495176  0.14846953 -0.20681677  0.20519419 -0.01227578  0.27092326\n",
      " -0.30503212 -0.396952    0.2070464 ]\n",
      "[-0.2889575   0.02451761 -0.19637751 -0.300913   -0.19051156  0.18494742\n",
      " -0.10821992  0.2839837  -0.25447561 -0.27520206  0.09573616 -0.22052826\n",
      "  0.24530608  0.10606701 -0.34334105]\n",
      "[ 0.13322368  0.22783593  0.3191812  -0.00409397  0.23082682 -0.35479263\n",
      "  0.21109005 -0.32662742  0.12534917 -0.26461153 -0.29021997  0.39751658\n",
      "  0.16373834  0.10285441  0.22476512]\n",
      "[ 0.01728808  0.34215955 -0.03588095  0.09528888  0.37256692  0.11487604\n",
      " -0.12982108  0.15715413  0.21080368 -0.08537171  0.11590957  0.32802395\n",
      " -0.14019733 -0.22710778  0.19426381]\n",
      "[-0.35635591 -0.2016496  -0.18391213 -0.36431691  0.32653431 -0.02214853\n",
      " -0.14035324  0.18237961  0.16501689 -0.33539285  0.05488124 -0.0466322\n",
      "  0.12131714  0.16823542  0.23932903]\n",
      "[  2.49524910e-01   7.98412106e-03  -7.11655851e-02   2.29634725e-01\n",
      "  -2.01917377e-01  -2.40757358e-01   2.70383597e-01  -2.14918144e-01\n",
      "   1.43479334e-01  -1.05189163e-01   6.53416003e-02  -4.17211974e-02\n",
      "   2.92410990e-01   1.72179469e-04   6.71666243e-02]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(mlp.coefs_[0])):\n",
    "    print mlp.coefs_[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important features (featureName, weigh of important, #column)\n",
      "('Bin6,z', 0.094601177728624003, 27)\n",
      "('Bin8,z', 0.094514202079460652, 29)\n",
      "('StdDev-y', 0.088663715958824732, 42)\n",
      "('Bin1,y', 0.073314365660696462, 12)\n",
      "('StdDev-x', 0.059735718431789854, 41)\n",
      "('Bin4,x', 0.059279068690570556, 5)\n",
      "('AvgAcc-x', 0.057088874101446675, 38)\n",
      "('Bin2,x', 0.054815846231073953, 3)\n",
      "('Bin1,x', 0.052483275917243243, 2)\n",
      "('TimeDiffPeaks-z', 0.036760004018860752, 34)\n",
      "('Bin7,x', 0.030140836529262457, 8)\n",
      "('TimeDiffPeaks-y', 0.030045072478452919, 33)\n",
      "('AvgResAcc', 0.030028617199406204, 44)\n",
      "('Bin10,y', 0.027736726851836167, 21)\n",
      "('Bin5,y', 0.027575073810641903, 16)\n",
      "('Bin6,x', 0.02719740608378847, 7)\n",
      "('Bin5,x', 0.025111970747539125, 6)\n",
      "('Bin6,y', 0.023000524959408113, 17)\n",
      "('Bin3,y', 0.019998883447374483, 14)\n",
      "('TimeDiffPeaks-x', 0.017952269665951284, 32)\n",
      "('Bin4,y', 0.014992725496758603, 15)\n",
      "('AvgAcc-y', 0.012952242472802076, 39)\n",
      "('Bin9,z', 0.0063358977150004426, 30)\n",
      "('Bin3,z', 0.003926208116920368, 24)\n",
      "('Bin2,z', 0.0011524895712103486, 23)\n",
      "('AvgAbsDiff-z', 0.0007448662223690346, 37)\n",
      "('Bin2,y', 0.0002135414126856657, 13)\n",
      "('Bin9,y', -0.0032593862349373486, 20)\n",
      "('Bin3,x', -0.0032713358908843413, 4)\n",
      "('AvgAbsDiff-x', -0.01376078145327401, 35)\n",
      "('Bin7,z', -0.018837944086226525, 28)\n",
      "('Bin4,z', -0.021237879024440635, 25)\n",
      "('Bin10,z', -0.022540428159141188, 31)\n",
      "('Bin7,y', -0.022603148622308746, 18)\n",
      "('StdDev-z', -0.026204515404177082, 43)\n",
      "('Bin8,y', -0.041485431902115281, 19)\n",
      "('Bin10,x', -0.04482254048824745, 11)\n",
      "('Bin1,z', -0.061501756109832856, 22)\n",
      "('Bin9,x', -0.065097947428170488, 10)\n",
      "('AvgAbsDiff-y', -0.079122550719252657, 36)\n",
      "('AvgAcc-z', -0.082531232755533895, 40)\n",
      "('Bin8,x', -0.093682864142762889, 9)\n",
      "('Bin5,z', -0.10761992439705731, 26)\n"
     ]
    }
   ],
   "source": [
    "avg_weight = []\n",
    "for i in range(0,len(mlp.coefs_[0])):\n",
    "    avg_weight.append(np.mean(mlp.coefs_[0][i]))\n",
    "print ('Important features (featureName, weigh of important, #column)')\n",
    "header = list(multi_layer_train.head(1))\n",
    "important_feature = []\n",
    "for i in range(0,len(avg_weight)):\n",
    "     important_feature.append((header[i+2],avg_weight[i],i+2))\n",
    "sorted_list = sorted(important_feature,key=lambda important_feature: important_feature[1],reverse=True)\n",
    "for j in range(0,len(sorted_list)):\n",
    "        first_imp_fea = sorted_list[0]\n",
    "        second_imp_fea = sorted_list[1]\n",
    "        print sorted_list[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
