{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from pandas import DataFrame,Series\n",
    "from matplotlib.colors import ListedColormap\n",
    "from random import sample\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Description of features\n",
    "#Average[3]: Average acceleration (for each axis)\n",
    "#Standard Deviation[3]: Standard deviation (for each axis)\n",
    "#Average Absolute Difference[3]: Average absolute\n",
    "#difference between the value of each of the 200 readings\n",
    "#within the ED and the mean value over those 200 values\n",
    "#(for each axis)\n",
    "#Average Resultant Acceleration[1]: Average of the square\n",
    "#roots of the sum of the values of each axis squared\n",
    "#over the ED\n",
    "#Time Between Peaks[3]: Time in milliseconds between\n",
    "#peaks in the sinusoidal waves associated with most\n",
    "#activities (for each axis)\n",
    "#Binned Distribution[30]: We determine the range of values\n",
    "#for each axis (maximum â€“ minimum), divide this range into\n",
    "#10 equal sized bins, and then record what fraction of the\n",
    "#200 values fell within each of the bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417\n"
     ]
    }
   ],
   "source": [
    "#Importing the dataset\n",
    "df_features = pd.read_csv(\"H:/mastersProject/activity_analyzer/LogisticRegression/Data/featuresfile.csv\")\n",
    "X_data = df_features.values[:, 2:45]\n",
    "y_data = df_features.values[:, 45]   \n",
    "print(len(df_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03526399 -0.09011814 -0.10221139 -0.06290793 -0.10322812 -0.00877184\n",
      "   0.13850888  0.03496695 -0.15027179 -0.07238832 -0.04812626 -0.27827872\n",
      "  -0.38236161 -0.32077681 -0.09129597 -0.15772183  0.20582751  0.28506861\n",
      "   0.17696472  0.06401973 -0.0288666   0.02158193  0.24815189  0.03405505\n",
      "  -0.03567522 -0.20763622 -0.2585398  -0.0425496  -0.04885906 -0.0985506\n",
      "  -0.01713979  0.44660761  0.36301354 -3.61336837 -2.85459234 -1.30610735\n",
      "   0.97316356  1.74839621 -3.60436639 -3.9937481  -3.25997307 -1.2012497\n",
      "   0.20187466]]\n",
      "Score of Logistic regression= 1.0\n"
     ]
    }
   ],
   "source": [
    "# Data 3 people for training the model\n",
    "lr = LogisticRegression(C=100.0, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.33, random_state = 42)\n",
    "probas = lr.fit(X_train, y_train)\n",
    "predict = lr.predict(X_test)\n",
    "logisticRegScore = lr.score(X_test, y_test)\n",
    "print(lr.coef_)\n",
    "print(\"Score of Logistic regression=\", logisticRegScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82  0]\n",
      " [ 0 56]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, predict, labels=[\"walking\", \"running\"])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.96666667  1.          1.          1.          0.96551724\n",
      "  1.          1.          1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Cross validation using KFold\n",
    "lr_data = pd.read_csv('H:/mastersProject/activity_analyzer/LogisticRegression/Data/featuresfile.csv')\n",
    "X = lr_data.values[:, 2:45]\n",
    "y = lr_data.values[:, 45]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "lr = LogisticRegression(C=100.0, random_state=1)\n",
    "lr.fit(X_train, y_train)\n",
    "kfold = StratifiedKFold(n_splits=32, random_state=1).split(X_train, y_train)\n",
    "scores = cross_val_score(estimator=lr, X=X_train, y=y_train, cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This model is overfitting as it has just 3 people data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
